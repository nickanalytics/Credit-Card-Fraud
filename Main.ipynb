{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages\n",
    "Note: main documentation for SweetViz can be found on: https://pypi.org/project/sweetviz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "import os\n",
    "import fastparquet\n",
    "# import dask.dataframe as dd\n",
    "# import feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('data/train.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column headers\n",
    "train.columns = train.columns.str.lower()\n",
    "train.columns = train.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map labels to training data and add to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('data/train_labels.csv')\n",
    "my_dict = train_label.set_index('customer_ID').to_dict()['target']\n",
    "train['target'] = train['customer_id'].map(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac =.01 = 1/100 deel\n",
    "df_train_sample_1 = train.sample(frac =.01, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some basic elements of the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55315, 191)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sample_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the sample from train (55315 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample_1.to_csv('train_sample_large.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates in the customer Id column (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate values in 'customer_id' column: 3118\n"
     ]
    }
   ],
   "source": [
    "num_duplicates = df_train_sample_1.duplicated(subset=['customer_id']).sum()\n",
    "print(\"Number of duplicate values in 'customer_id' column:\", num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample_1 = df_train_sample_1.drop_duplicates(subset=['customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save df_train_sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample_1.to_csv('df_train_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a smaller dataset (5000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_small = pd.read_csv('data\\df_sample_500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SweetViz Report of the Sample Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the DataFrame with Sweetviz\n",
    "report = sv.analyze(df_train_sample_1, target_feat='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Report_large.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "---\n",
      "WARNING: one or more correlations had an edge-case/error and a 1.0 correlation was assigned\n",
      "(likely due to only having a single row, containing non-NaN values for both correlated features)\n",
      "Affected correlations:['d_73/d_134', 'd_88/d_134', 'd_134/d_73', 'd_134/d_88']\n"
     ]
    }
   ],
   "source": [
    "report.show_html(\"Report_large.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other use cases of SweetViz (not used)\n",
    "https://pypi.org/project/sweetviz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_report = sv.analyze(my_dataframe)\n",
    "my_report.show_html() # Default arguments will generate to \"SWEETVIZ_REPORT.html\"\n",
    "\n",
    "# analyze arguments:\n",
    "# analyze(source: Union[pd.DataFrame, Tuple[pd.DataFrame, str]],\n",
    "#             target_feat: str = None,\n",
    "#             feat_cfg: FeatureConfig = None,\n",
    "#             pairwise_analysis: str = 'auto',\n",
    "#             verbosity: str = 'default'):\n",
    "feature_config = sv.FeatureConfig(skip=\"PassengerId\", force_text=[\"Age\"])\n",
    "# \n",
    "\n",
    "# Comparing two dataframes (e.g. Test vs Training sets)\n",
    "my_report = sv.compare([my_dataframe, \"Training Data\"], [test_df, \"Test Data\"], \"Survived\", feature_config)\n",
    "\n",
    "# Comparing two features\n",
    "my_report = sv.compare_intra(my_dataframe, my_dataframe[\"Sex\"] == \"male\", [\"Male\", \"Female\"], \"Survived\", feature_config)\n",
    "\n",
    "# Show:\n",
    "show_html(  filepath='SWEETVIZ_REPORT.html', \n",
    "            open_browser=True, \n",
    "            layout='widescreen', \n",
    "            scale=None)\n",
    "\n",
    "show_notebook(  w=None, \n",
    "                h=None, \n",
    "                scale=None,\n",
    "                layout='widescreen',\n",
    "                filepath=None,\n",
    "                file_layout=None,\n",
    "                file_scale=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensionality (leave only 38 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['customer_id','r_4','r_2','b_33','r_13','b_30','b_22','r_10','r_24','r_21','d_87','s_20','b_38','b_33','b_22','b_30','d_51','r_2','r_10','p_2','d_48','d_61','b_18','b_9','b_2','d_75','d_55','d_58','d_44','b_3','b_7','b_23','d_74','b_8','r_3','p_4','d_112','r_16', 'target']\n",
    "\n",
    "# Reduce DataFrame to include only the columns in the keep list\n",
    "df_train_sample_1_reduced = df_train_sample_1.loc[:, keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55315, 38)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sample_1_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id       0\n",
       "r_4               0\n",
       "r_2               0\n",
       "b_33              0\n",
       "r_13              0\n",
       "b_30              0\n",
       "b_22              0\n",
       "r_10              0\n",
       "r_24              0\n",
       "r_21              0\n",
       "d_87              0\n",
       "s_20              0\n",
       "b_38              0\n",
       "b_33              0\n",
       "b_22              0\n",
       "b_30              0\n",
       "d_51              0\n",
       "r_2               0\n",
       "r_10              0\n",
       "p_2             443\n",
       "d_48           7207\n",
       "d_61           6052\n",
       "b_18              0\n",
       "b_9               0\n",
       "b_2              21\n",
       "d_75              0\n",
       "d_55           1779\n",
       "d_58              0\n",
       "d_44              0\n",
       "b_3              21\n",
       "b_7               0\n",
       "b_23              0\n",
       "d_74              0\n",
       "b_8             232\n",
       "r_3               0\n",
       "p_4               0\n",
       "d_112            25\n",
       "r_16              0\n",
       "target            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sample_1_reduced.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample_1_reduced.to_csv('train_reduced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-mixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
